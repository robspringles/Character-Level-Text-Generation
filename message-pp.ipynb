{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pre-processing the message data as input to the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Search for digits (ie user name or user id?)\n",
    "digits = re.compile(\"\\d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download your Facebook message data and put the messages.htm file in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the html file\n",
    "print(\"\\nReading file...\\n\")\n",
    "htm = urllib.request.urlopen(\"file:messages.htm\").read()\n",
    "print(htm[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMaking soup...\\n\")\n",
    "soup = BeautifulSoup(htm, \"lxml\")\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format of the message data:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "</div, class = thread>\n",
    "    <div class = message_header>\n",
    "        <span, class = user and class = meta></span>\n",
    "        <p>message</p>\n",
    "    </div>\n",
    "    ...next messages further back in time\n",
    "</div, class = thread>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get threads\n",
    "print(\"Looking for threads\")\n",
    "Threads = soup.findAll(class_=\"thread\")\n",
    "print(\"\\nFound \", len(Threads), \" threads\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the name by the facebook address with the user ID\n",
    "# 'user' variable is of the form '100001785489441@facebook.com'\n",
    "# we extract the user id, open the facebook page of the user and get the\n",
    "# real name\n",
    "# Does not always work so we catch exceptions and print out to manually update\n",
    "# Save them in a dict for quicker access\n",
    "\n",
    "# Empty dict\n",
    "user_dict = {}\n",
    "# Load saved dict\n",
    "user_dict = np.load('user_dict.npy').item()\n",
    "def getUser(user_id):\n",
    "    if user_id in user_dict:\n",
    "        return user_dict[user_id]\n",
    "    try:\n",
    "        fb = urllib.request.urlopen(\"https://www.facebook.com/\" + user_id).read()\n",
    "        fb_soup = BeautifulSoup(fb, \"lxml\")\n",
    "        user = fb_soup.title.getText().split(\"|\")[0]\n",
    "        # Corner case for getting \"security check\" rather than user name\n",
    "        if \"Security\" in user: \n",
    "            print(\"Could not extract user's name: https://www.facebook.com/\" + user_id)\n",
    "            user = input()\n",
    "            user_dict[user_id] = user\n",
    "            return user\n",
    "        user_dict[user_id] = user\n",
    "        return user\n",
    "    except:\n",
    "        print(\"Could not extract user's name: https://www.facebook.com/\" + user_id)\n",
    "        user = input()\n",
    "        user_dict[user_id] = user\n",
    "        return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all messages in each thread to a new file\n",
    "i = 1\n",
    "total_extracted = 0\n",
    "LENGTH_FOR_THREAD = 50 # Only conversations over a certain number of messages\n",
    "DATE_FOR_THREAD = 2017 # Only threads with recent activity are considered\n",
    "DATE_FOR_MESSAGE = 2015 # Only more recent messages within considered threads are kept\n",
    "for thread in Threads:\n",
    "    messages = thread.findAll(class_=\"message_header\")\n",
    "    # Check most recent activity\n",
    "    if int(messages[0].find(class_=\"meta\").getText().split(',')[1].split()[2]) < DATE_FOR_THREAD:\n",
    "        continue\n",
    "    # Check conversation length\n",
    "    if len(messages) < LENGTH_FOR_THREAD:\n",
    "        continue\n",
    "    print(\"=\"*125)\n",
    "    print(\"\\nThread #\",i)\n",
    "    print(len(messages), \" messages\\n\")\n",
    "    message_path = \"./messages/messages-\"+str(i)+\".txt\"\n",
    "    with open(message_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for j,message_header in enumerate(messages):\n",
    "            text = message_header.find_next(\"p\").getText()\n",
    "            user = message_header.find_next(class_=\"user\").getText()\n",
    "            meta = message_header.find(class_=\"meta\").getText()\n",
    "            # Check message age\n",
    "            if int(meta.split(',')[1].split()[2]) < DATE_FOR_THREAD:\n",
    "                continue\n",
    "            total_extracted += 1\n",
    "            if not user or digits.search(user):\n",
    "                user_id = user.split('@')[0]\n",
    "                user = getUser(user_id)\n",
    "            \n",
    "            if text!=None and user!=None and meta!=None:\n",
    "                #file.write(meta)\n",
    "                file.write(\"\\n\"+user)\n",
    "                file.write(\"\\n\\t\"+text+\"\\n\")\n",
    "            else:\n",
    "                print (\"\\nCouldn't write row\\n\")\n",
    "                print (\"\\n\", message_header, \"\\n\")\n",
    "            # Print for progress\n",
    "            if j < 5:\n",
    "                #print(meta)\n",
    "                print(user)\n",
    "                print(\"\\t\",text,\"\\n\")\n",
    "    print(\"Written to \", message_path)\n",
    "    i+=1\n",
    "print(\"\\n\\n Completed pre-processing {} messages extracted.\\n\".format(total_extracted))\n",
    "# Save user dict to file\n",
    "np.save(\"user_dict.npy\", user_dict)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
